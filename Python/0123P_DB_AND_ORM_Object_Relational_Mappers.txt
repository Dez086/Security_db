
https://www.fullstackpython.com/databases.html
s

SQLite is a database that is stored in a single file on disk.
PostgreSQL and MySQL are two of the most common open source databases

Software
    DBeaver - Open source - db in general
    PGadmin - Postgres
    

*******************************************************************************
                                DBs
*******************************************************************************

Libraries for relational databases:
    psycopg2 for PostgreSQL.
		https://github.com/psycopg/psycopg2		https://www.psycopg.org/
    MySQLdb (MySQL-python) for MySQL. Development is mostly frozen. (2014)
		https://github.com/farcepest/MySQLdb1
    cx_Oracle for Oracle Database (source code).
		https://github.com/oracle/python-cx_Oracle
	SQLite is built into Python. import sqlite3

Object-relational mappers (ORMs)
	https://www.fullstackpython.com/object-relational-mappers-orms.html

Database third-party services: database servers as a hosted service.
    Amazon Relational Database Service (RDS)
		pre-configured MySQL and PostgreSQL instances.
		http://aws.amazon.com/rds/
    Google Cloud SQL. MySQL instances.
		https://developers.google.com/cloud-sql/
    BitCan provides both MySQL and MongoDB hosted databases
		http://www.gobitcan.com/
    ElephantSQL is a software-as-a-service, hosts PostgreSQL, on top of AWS.
		https://www.elephantsql.com/

Databases learning checklist

    Install PostgreSQL on your server. sudo apt-get install postgresql.
    Make sure the psycopg2 library is in your application's dependencies.
		http://initd.org/psycopg/
    Configure your web application to connect to the PostgreSQL instance.
    Create models in your ORM,
		either with Django's built-in ORM
			https://docs.djangoproject.com/en/dev/topics/db/
		or SQLAlchemy with Flask.
			http://www.sqlalchemy.org/
    Build your database tables or sync the ORM models with the PostgreSQL
		instance, if you're using an ORM. --> Alembic
    Start creating, reading, updating and deleting data in the database from
		your web application.


*******************************************************************************
						ORM
*******************************************************************************

https://www.fullstackpython.com/object-relational-mappers-orms.html

https://docs.sqlalchemy.org/en/13/orm/tutorial.html

https://www.sqlalchemy.org/
	The Python SQL Toolkit and Object Relational Mapper
https://flask-sqlalchemy.palletsprojects.com/en/2.x/

Web framework	None				Flask			Flask			Django
				+----------------------------------------------+
ORM				| SQLAlchemy		SQLAlchemy		SQLAlchemy |	Django ORM
				|_____________________________________[+ ORM]__|
DB CONNECTOR	(builtin stdlib)	MySQL-python	psycopg			psycopg
relational DB	SQLite				MySQL			PostgreSQL		PostgreSQL


Python ORM Implementations:
	SQLAlchemy		https://www.fullstackpython.com/sqlalchemy.html
    Peewee			https://www.fullstackpython.com/peewee.html
    The Django ORM	https://www.fullstackpython.com/django-orm.html
    PonyORM			https://www.fullstackpython.com/pony-orm.html
    SQLObject		http://sqlobject.org/
    Tortoise ORM (source code)	 https://tortoise-orm.readthedocs.io/en/latest/



*******************************************************************************
                                    MySQLdb
*******************************************************************************

https://pypi.org/project/MySQL-python/

[sudo apt-get install python3-dev]
sudo apt-get install libmysqlclient-dev
sudo apt-get install zlib1g-dev
sudo pip3 install mysqlclient==1.3.10
...
python3
>>> import MySQLdb
>>> MySQLdb.__version__ 
'1.3.10'


*******************************************************************************

import MySQLdb
db=MySQLdb.connect(passwd="moonpie",db="thangs")

c = db.cursor()			""" To perform a query, you first need a cursor"""

These cursor classes store their results on the server and feed them to your
program as you request them. You have to retreive all of the results and close
the cursor before you can execute additional queries. 

max_price = 5
c.execute("""SELECT spam, eggs, sausage FROM breakfast
          WHERE price < %s""", (max_price,))

>>> c.fetchone()	# The result. returns a single tuple, which is the row
(3L, 2L, 0L)		# returns None when there are no more rows to fetch.

c.fetchall(). 		# return a sequence of rows.

c.fetchmany(n)		# return a sequence of rows.
	the n is optional and defaults to c.arraysize, normally 1.

If you use a weird cursor class, the rows themselves might not be tuples.

c.executemany(
      """INSERT INTO breakfast (name, spam, eggs, sausage, price)
      VALUES (%s, %s, %s, %s, %s)""",
      [
      ("Spam and Sausage Lover's Plate", 5, 1, 8, 7.95 ),
      ("Not So Much Spam Plate", 3, 2, 0, 3.95 ),
      ("Don't Wany ANY SPAM! Plate", 0, 4, 3, 5.95 )
      ] )


*******************************************************************************

***

https://mysqlclient.readthedocs.io/user_guide.html#mysqldb

db = MySQLdb.connect(host="localhost", port=3306, user=argv[1],
                         passwd=argv[2], db=argv[3], charset="utf8")
cur = db.cursor()

numrows = cur.execute("SELECT * FROM song")
print "Selected %s rows" % numrows      
print "Selected %s rows" % cur.rowcount				// PREFERED WAY, USING CUR

cur.execute("SELECT * FROM song WHERE id = %s or id = %s", (1,2))

cur.execute("INSERT INTO song (title) VALUES (%s)", song)

***

# Print results in comma delimited format
cur.execute("SELECT * FROM song")
rows = cur.fetchall()
for row in rows:
    for col in row:
        print "%s," % col
    print "\n"

***

cur.execute("SELECT * FROM song WHERE id = 1")
print "Id: %s -- Title: %s" % cur.fetchone()

***

# Get data from database
try:
    cur.execute("SELECT * FROM song")
    rows = cur.fetchall()
except MySQLdb.Error, e:
    try:
        print "MySQL Error [%d]: %s" % (e.args[0], e.args[1])
    except IndexError:
        print "MySQL Error: %s" % str(e)
# Print results in comma delimited format
for row in rows:
    for col in row:
        print "%s," % col
    print "\n"

***

# Close all cursors
cur.close()
# Close all databases
db.close()

***


*******************************************************************************


*******************************************************************************
						SQLAlchemy
*******************************************************************************
https://docs.sqlalchemy.org/en/14/orm/tutorial.html

pip3 install SQLAlchemy==1.2.5
...
python3
>>> import sqlalchemy
>>> sqlalchemy.__version__ 
'1.2.5'

*******************************************************************************

https://docs.sqlalchemy.org/en/14/core/engines.html
https://docs.sqlalchemy.org/en/14/core/type_basics.html
https://auth0.com/blog/sqlalchemy-orm-tutorial-for-python-developers/


engine = create_engine('dialect+driver://username:password@host:port/database')
Base.metadata.create_all(engine)


PostgreSQL dialect uses psycopg2 as the default DBAPI. pg8000 is also available
as a pure-Python substitute:
	# default
	engine = create_engine('postgresql://scott:tiger@localhost/mydatabase')
	# psycopg2
	engine = create_engine('postgresql+psycopg2://scott:tiger@localhost/mydatabase')
	# pg8000
	engine = create_engine('postgresql+pg8000://scott:tiger@localhost/mydatabase')

MySQL dialect uses mysql-python as the default DBAPI. There are many MySQL
DBAPIs available, including MySQL-connector-python and OurSQL:
	# default
	engine = create_engine('mysql://scott:tiger@localhost/foo')
	# mysqlclient (a maintained fork of MySQL-Python)
	engine = create_engine('mysql+mysqldb://scott:tiger@localhost/foo')
	# PyMySQL
	engine = create_engine('mysql+pymysql://scott:tiger@localhost/foo')

SQLite connects to file-based databases,
using the Python built-in module sqlite3 by default.
As SQLite connects to local files, the URL format is slightly different.
The “file” portion of the URL is the filename of the database.
For a relative file path, this requires three slashes:
	# sqlite://<nohostname>/<path>
	# where <path> is relative:
		engine = create_engine('sqlite:///foo.db')

And for an absolute file path, three slashes are followed by the absolute path:
	# Unix/Mac - 4 initial slashes in total
		engine = create_engine('sqlite:////absolute/path/to/foo.db')
	# Windows
		engine = create_engine('sqlite:///C:\\path\\to\\foo.db')
	# Windows alternative using raw string
		engine = create_engine(r'sqlite:///C:\path\to\foo.db')

To use a SQLite :memory: database, specify an empty URL:
	engine = create_engine('sqlite://')


*******************************************************************************

https://docs.sqlalchemy.org/en/13/orm/extensions/declarative/basic_use.html

Classes mapped using the Declarative system are defined in terms of a base
class which maintains a catalog of classes and tables relative to that base -
this is known as the declarative base class. Our application will usually have
just one instance of this base in a commonly imported module. We create the
base class using the declarative_base() function, as follows:



if __name__ == "__main__":
    from sqlalchemy import create_engine
    from sqlalchemy.orm import sessionmaker

    from sys import argv
	from datetime import date
	from base_model import Base, Stuntman

    engine = create_engine(				# 1 - Create engine to communicate DB
        'mysql+mysqldb://{}:{}@localhost/{}'.format(argv[1], argv[2],
		argv[3]), pool_pre_ping=True)
	Base.metadata.create_all(engine)	# 2 - generate database schema
    Session = sessionmaker(bind=engine)	# 3 - SQLAlchemy ORM session factory bound to this engine
	session = Session()					# 4 - create a new session

	wahl = Actor("Mark Wahlberg", date(1971, 6, 5))			# 5 - instances
	mark = Stuntman("Richard Roe", True, wahl)
    louisiana = State(name='Louisiana')

    states = session.query(State).order_by(State.id).all()	# 6 - Query

    for state in states:				# 7 - Use query results
		print("{}: {}".format(state.id, state.name))

	session.add(mark_stuntman)				# 8 - persists data	
	session.commit()						# 9 - commit session

	two = session.query(State).filter_by(id=2).first()		# UPDATE
	two.name = 'New Mexico'
	session.commit()

	session.close()							# 10 - close session

****
Stuntman.py class

from sqlalchemy import Column, String, Integer, Boolean, ForeignKey
from sqlalchemy.orm import relationship, backref
from sqlalchemy.ext.declarative import declarative_base

Base = declarative_base()

class Stuntman(Base):
    __tablename__ = 'stuntmen'

    id = Column(Integer, primary_key=True)
    name = Column(String)
    active = Column(Boolean)
    actor_id = Column(Integer, ForeignKey('actors.id'))
    actor = relationship("Actor", backref=backref("stuntman", uselist=False))

    def __init__(self, name, active, actor):
        self.name = name
        self.active = active
        self.actor = actor
***


*******************************************************************************
                            Queries with SQLAlcheny
*******************************************************************************
https://docs.sqlalchemy.org/en/13/orm/query.html

Query API for Querys

				Returns
	all():		List of objects
    count(): 	Total number of rows of a query.
    filter(): 	Filters the query by applying a criteria.
    delete(): 	Removes from the database the rows matched by a query.
    distinct(): Applies a distinct statement to a query.
    exists(): 	Adds an exists operator to a subquery.
    first():	Object, the first row in a query.
    get(): 		row referenced by the primary key parameter passed as argument.
    join(): Creates a SQL join in a query.
    limit(): Limits the number of rows returned by a query.
    order_by(): Sets an order in the rows returned by a query.

session.query(Movie) \
    .filter(Movie.release_date > date(2015, 1, 1)) \
    .all()

session.query(Movie) \
    .join(Actor, Movie.actors) \
    .filter(Actor.name == 'Dwayne Johnson') \
    .all()

session.query(Actor) \
    .join(ContactDetails) \
    .filter(ContactDetails.address.ilike('%glendale%')) \
    .all()



*******************************************************************************
                            Upsert with SQLAlcheny
*******************************************************************************
https://stackoverflow.com/questions/55368162/bulk-upsert-with-sqlalchemy-postgres/55369524
https://docs.sqlalchemy.org/en/14/dialects/postgresql.html#insert-on-conflict-upsert
https://stackoverflow.com/questions/25955200/sqlalchemy-performing-a-bulk-upsert-if-exists-update-else-insert-in-postgr/26018934#26018934
https://stackoverflow.com/questions/25955200/sqlalchemy-performing-a-bulk-upsert-if-exists-update-else-insert-in-postgr/26018934#26018934

def write_records(records: Iterable[VideoRecord]):
    db = get_client().get_database(MONGO_DBNAME)
    post_coll = db.get_collection("facebook_posts")
    write_ops = []

    session = Session(engine)
    insp = Inspector.from_engine(engine)
    table_name = FacebookVideoPost.__table__
    https://stackoverflow.com/questions/33878830/sqlalchemy-determine-if-unique-constraint-exists
    table_constraint = insp.get_unique_constraints(table_name)[0].get('name')
    video_list = []

    for r in video_records:
        # MongoDB
        rd = asdict(r)
        rid = rd.pop("metric_sample_id")
        upsert = ReplaceOne(dict(_id=rid), rd, upsert=True)
        write_ops.append(upsert)
        # PostgreSQL session
        #  rd = asdict(r)
        #  new_video = FacebookVideoPost()
        #  new_video.__dict__.update(rd)
        #  video_list.append(new_video)
        #PostgreSQL INSERT
        #  insert_stmt = insert(new_video.__table__).values(rd)
        #  session.execute(update_statement)
        #  session.commit()
        #PostgreSQL INSERT…ON CONFLICT (Upsert)  facebook_video_post_metric_sample_id_key
        rd = asdict(r)
        insert_stmt = insert(table_name).values(rd)
        update_columns = {
            col.name: col for col in insert_stmt.excluded if col.name not in ('id', 'metric_sample_id')}
        update_statement = insert_stmt.on_conflict_do_update(
            constraint=table_constraint,
            set_=update_columns)
        session.execute(update_statement)
        session.commit()
    if video_list:
        # PostgreSQL session
        #  session.add_all(video_list)
        #  session.commit()
        pass
    session.close()



*******************************************************************************
                            Select with SQLAlcheny
*******************************************************************************

https://towardsdatascience.com/sqlalchemy-python-tutorial-79a577141a91
https://docs.sqlalchemy.org/en/14/tutorial/data_select.html?highlight=select

def last_video_in_page(page_id: int):
    session = Session(engine)
    table_name = FacebookVideo.__table__

    # select video_id from facebook_video
    # where page_id = page_id
    # order by created_time desc 
    # limit 1;
    result = session.execute(
        select([table_name.columns.video_id])
        .where(table_name.columns.page_id == page_id)
        .order_by(desc(table_name.columns.created_time))
    ).fetchmany(1)  # can used inside a loor or .fetchall() to get all results.

    # Perform one request to DB with all statements stored in session
    session.commit()
    session.close()
    return result


*******************************************************************************
                            Disconnect Handling
*******************************************************************************

https://docs.sqlalchemy.org/en/14/core/pooling.html#pool-disconnects
https://docs.sqlalchemy.org/en/14/faq/connections.html#faq-execute-retry
https://docs.sqlalchemy.org/en/14/core/connections.html#dbapi-autocommit

engine = create_engine(
    DB_URL,
    future=True,  # this opts-in to most current (2.0) ORM conventions
    pool_size=10,
    max_overflow=SIMULTANEOUS_CONNECTIONS,
    pool_pre_ping=True,  # tests connections for liveness upon each checkout
)

from sqlalchemy import create_engine, exc
e = create_engine(...)
c = e.connect()
try:
    # suppose the database has been restarted.
    c.execute(text("SELECT * FROM table"))
    c.close()
except exc.DBAPIError, e:
    # an exception is raised, Connection is invalidated.
    if e.connection_invalidated:
        print("Connection was invalidated!")
# after the invalidate event, a new connection
# starts with a new Pool
c = e.connect()
c.execute(text("SELECT * FROM table"))



*******************************************************************************
                                Session
*******************************************************************************

https://docs.sqlalchemy.org/en/14/orm/session_basics.html#using-a-sessionmaker

https://docs.sqlalchemy.org/en/14/core/pooling.html#pool-disconnects
https://docs.sqlalchemy.org/en/14/faq/connections.html#faq-execute-retry


# In a module (global)
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
# an Engine, which the Session will use for connection resources
engine = create_engine(
    'postgresql://scott:tiger@localhost/',
    future=True,  # this opts-in to most current (2.0) ORM conventions
    pool_size=10,
    max_overflow=SIMULTANEOUS_CONNECTIONS,
    pool_pre_ping=True,  # tests connections for liveness upon each checkout
)
# a sessionmaker(), also in the same scope as the engine 
Session = sessionmaker(engine)

# In a script
# Construct a Session() and include begin()/commit()/rollback() at once
with Session.begin() as session:  # commits the transaction, closes the session
    session.add(some_object)
    session.add(some_other_object)





CAST ( expression AS target_type );
expression::type


""" Module with functions to access FB tables in postgres database """

from typing import Any, Iterable, List, Dict
from dataclasses import asdict
from orm.models import engine  # pylint: disable=import-error
from sqlalchemy.orm import Session
from orm.models.fb import (  # pylint: disable=import-error, ungrouped-imports
    FacebookVideoPost,
    FacebookVideo,
)
from sqlalchemy import inspect, select, desc
from sqlalchemy.dialects.postgresql import insert
from analytics_models import AnalyticsVideoRecord


def write_video_records_to_postgresql(video_records: Iterable[AnalyticsVideoRecord]):
    """Store insights of video post in the facebook_video_post table using UPSERT."""

    # Create session and add objects, inner context calls session.commit()
    # If there were no exceptions, outer context calls session.close()
    with Session(engine) as session, session.begin():
        insp = inspect(engine)
        table_name = FacebookVideoPost.__table__
        table_constraint = insp.get_unique_constraints(table_name)[0]["name"]

        for record in video_records:
            record_dict = asdict(record)
            # Changing _id (used in MongoDB) by metric_sample_id used in fb table.
            record_dict.update({"metric_sample_id": record_dict["_id"]})
            del record_dict["_id"]
            # PostgreSQL INSERT…ON CONFLICT (Upsert)
            insert_stmt = insert(table_name).values(record_dict)
            update_columns = {
                col.name: col
                for col in insert_stmt.excluded
                if col.name not in ("id", "metric_sample_id")
            }
            update_statement = insert_stmt.on_conflict_do_update(
                constraint=table_constraint, set_=update_columns
            )
            # Store in session all statements to be executed
            session.execute(update_statement)


def write_videos_list_to_postgresql(videos_list: List):
    """Store a list of videos in the facebook_video table using UPSERT."""

    if not videos_list:
        return

    # Create session and add objects, inner context calls session.commit()
    # If there were no exceptions, outer context calls session.close()
    with Session(engine) as session, session.begin():
        insp = inspect(engine)
        table_name = FacebookVideo.__table__
        # This UNIQUE constrain is used to compare in case of insert conflicts,
        # so the UPSERT operation can be executed (i.e if a page_video_id already exists
        # in DB, an UPDATE is executed instead of an INSERT).
        table_constraint = insp.get_unique_constraints(table_name)[0]["name"]

        for record in videos_list:
            # PostgreSQL INSERT…ON CONFLICT (Upsert)
            insert_stmt = insert(table_name).values(record)
            update_columns = {
                col.name: col
                for col in insert_stmt.excluded
                if col.name not in ("id", "page_video_id")
            }
            update_statement = insert_stmt.on_conflict_do_update(
                constraint=table_constraint, set_=update_columns
            )
            # Store in session all statements to be executed
            session.execute(update_statement)


def last_created_time_in_page(page_id: int) -> int:
    """Retrieve the created_time of the most recent video in a fb page (page_id) and
    returns the equivalent POSIX timestamp (integer) or zero if no records exist."""

    # Create session and add objects, inner context calls session.commit()
    # If there were no exceptions, outer context calls session.close()
    with Session(engine) as session, session.begin():
        table_name = FacebookVideo.__table__

        # SQL query to execute:
        #   SELECT video_id FROM facebook_video
        #   WHERE page_id = page_id
        #   ORDER BY created_time desc
        #   LIMIT 1;
        # Use .scalar when the result contains only single value.
        # Change to .fetchmany(int n) to load optimal number of rows.
        # Change to .fetchall() to load all rows.
        result = session.execute(
            select(table_name.columns.created_time)
            .where(table_name.columns.page_id == page_id)
            .order_by(desc(table_name.columns.created_time))
        ).scalar()

    if result:
        return int(result.timestamp())
    # This means there are no records for this page_id, so we gather all
    # from the beginning of times.
    return 0


def get_videos_list_from_db(page_id: int) -> List[Dict[str, Any]]:
    """Retrieve the data of all videos for fb page (page_id) from the database"""

    # Create session and add objects, inner context calls session.commit()
    # If there were no exceptions, outer context calls session.close()
    with Session(engine) as session, session.begin():
        table_name = FacebookVideo.__table__

        # SQL query to execute:
        #   SELECT * FROM facebook_video
        #   WHERE page_id = page_id;
        # Use .scalar when the result contains only single value.
        # Change to .fetchmany(int n) to load optimal number of rows.
        # Change to .fetchall() to load all rows.
        result = session.execute(
            select(table_name).where(table_name.columns.page_id == page_id)
        )

    # Return a list of dictionaries where each item has the columns as keys.
    return list(result.mappings().fetchall())


*******************************************************************************
                WHERE/FILTER A JSON FIELD
*******************************************************************************

https://docs.sqlalchemy.org/en/13/core/type_basics.html?highlight=json#sqlalchemy.types.JSON

SELECT COUNT(*) FROM table1
WHERE field1 = 'con' AND json_field#>>'{metadata,URL}' LIKE 'http%http%';
"""
with engine.connect() as conn:
    metadatas = conn.execute(
        select(Table1.json_field)
        .where(Table1.field1 == "con")
        .filter(
            text(
                "json_field#>>'{metadata,wURL}' LIKE 'http%http%'"
            )
        )
    ).fetchall()


JSON-Specific Expression Operators

The JSON datatype provides these additional SQL operations:

Keyed index operations:
data_table.c.data['some key']

Integer index operations:
data_table.c.data[3]

Path index operations:
data_table.c.data[('key_1', 'key_2', 5, ..., 'key_n')]

Data casters for specific JSON element types, subsequent to an index or path operation being invoked:
data_table.c.data["some key"].as_integer()



*******************************************************************************
                    update
*******************************************************************************

    with engine.connect() as conn:
        conn.execute(
            update(table1)
            .where(table1.id == i)
            .values(request_body_json=new_metadata)
        )
        conn.commit()


*******************************************************************************
                    raw query - text
*******************************************************************************

t = text("select response_status_code from ugc_upload_notification where id= 31217;")
with engine.connect() as conn:
    metadatas = conn.execute(t)










